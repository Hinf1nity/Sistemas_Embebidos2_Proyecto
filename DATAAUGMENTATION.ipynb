{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "video_dir = 'CUANDO'  # Directorio de los videos originales\n",
    "output_dir = 'CUANDO_AUG'  # Directorio de salida para los videos generados\n",
    "start_index = 161  # Índice inicial para el nombre de los videos generados\n",
    "\n",
    "# Obtener la lista de videos en el directorio\n",
    "video_files = os.listdir(video_dir)\n",
    "#obtener nombre de la carpeta\n",
    "file_name = os.path.basename(video_dir)\n",
    "print (file_name)\n",
    "aux=\"aug\"\n",
    "\n",
    "# Recorrer cada video\n",
    "for video_file in video_files:\n",
    "    # Obtener el nombre y la extensión del archivo\n",
    "    video_name, extension = os.path.splitext(video_file)\n",
    "\n",
    "    # Ruta completa del video de entrada\n",
    "    input_video_path = os.path.join(video_dir, video_file)\n",
    "\n",
    "    # Leer el video original\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "    # Obtener la cantidad de cuadros en el video original\n",
    "    num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Crear los nombres de los videos generados\n",
    "    output_video_name1 = f'{file_name}{start_index}{aux}{extension}'\n",
    "    output_video_name2 = f'{file_name}{start_index + 1}{aux}{extension}'\n",
    "\n",
    "    # Rutas completas de los videos generados\n",
    "    output_video_path1 = os.path.join(output_dir, output_video_name1)\n",
    "    output_video_path2 = os.path.join(output_dir, output_video_name2)\n",
    "\n",
    "    # Crear el objeto VideoWriter para el primer video generado\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out1 = cv2.VideoWriter(output_video_path1, fourcc, 30, (704, 396))\n",
    "\n",
    "    # Crear el objeto VideoWriter para el segundo video generado\n",
    "    out2 = cv2.VideoWriter(output_video_path2, fourcc, 30, (704, 396))\n",
    "\n",
    "    # Leer cada cuadro del video original y aplicar las transformaciones\n",
    "    for frame_index in range(num_frames):\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Aplicar la función cv2.rotate() al primer video generado\n",
    "        M1 = np.float32([[1, 0, 60], [0, 1, 0]])\n",
    "        translated_frame1 = cv2.warpAffine(frame, M1, (frame.shape[1], frame.shape[0]))\n",
    "        M2 = np.float32([[1, 0, -60], [0, 1, 0]])\n",
    "        translated_frame2 = cv2.warpAffine(frame, M2, (frame.shape[1], frame.shape[0]))\n",
    "        #rotated_frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "\n",
    "        # Aplicar la función cv2.warpAffine() al segundo video generado\n",
    "        #M = cv2.getRotationMatrix2D((128 / 2, 128 / 2), 30, 1)\n",
    "        #warped_frame = cv2.warpAffine(frame, M, (128, 128))\n",
    "\n",
    "        # Escribir los cuadros en los videos generados\n",
    "        out1.write(translated_frame1)\n",
    "        out2.write(translated_frame2)\n",
    "\n",
    "    # Liberar los recursos\n",
    "    cap.release()\n",
    "    out1.release()\n",
    "    out2.release()\n",
    "\n",
    "    # Aumentar el índice para el siguiente par de videos generados\n",
    "    start_index += 2"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
