{"cells":[{"cell_type":"code","execution_count":null,"id":"6b83a450","metadata":{"id":"6b83a450","outputId":"2a6ac6ea-2a0d-465f-8f4f-eb1d2be2233f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 2040 files belonging to 5 classes.\n","Found 360 files belonging to 5 classes.\n","<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 640, 396, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n","['CUANDO', 'DERECHA', 'DISMINUIR', 'IZQUIERDA', 'SI']\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","import keras\n","import numpy as np\n","\n","# Cargar los datos de entrenamiento y validación\n","ds_train = tf.keras.preprocessing.image_dataset_from_directory(\n","    'TRAINDS',\n","    labels='inferred',\n","    label_mode=\"int\",\n","    batch_size=32,\n","    shuffle=True,\n","    seed=123,\n",")\n","\n","ds_val = tf.keras.preprocessing.image_dataset_from_directory(\n","    'VALDS',\n","    labels='inferred',\n","    label_mode=\"int\",\n","    batch_size=32,\n","    shuffle=True,\n","    seed=123,\n",")\n","\n","# Redimensionar las imágenes en el conjunto de datos de entrenamiento\n","resized_ds_train = ds_train.map(lambda x, y: (tf.image.resize(x, (640, 396)), y))\n","\n","# Redimensionar las imágenes en el conjunto de datos de validación\n","resized_ds_val = ds_val.map(lambda x, y: (tf.image.resize(x, (640, 396)), y))\n","\n","# Obtener la lista de clases\n","clase = ds_train.class_names\n","\n","# Preparar los conjuntos de datos para un rendimiento óptimo\n","AUTOTUNE = tf.data.AUTOTUNE\n","resized_ds_train = resized_ds_train.cache().prefetch(buffer_size=AUTOTUNE)\n","\n","print (resized_ds_train)\n","resized_ds_val = resized_ds_val.cache().prefetch(buffer_size=AUTOTUNE)\n","\n","# Definir el número de clases y construir el modelo\n","num_classes = 7\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Rescaling(1./255, input_shape=(640, 396, 3)),\n","    tf.keras.layers.Conv2D(16, 3, activation='relu'),\n","    tf.keras.layers.MaxPooling2D(),\n","    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n","    tf.keras.layers.MaxPooling2D(),\n","    tf.keras.layers.Conv2D(64, 3, activation='relu'),\n","    tf.keras.layers.MaxPooling2D(),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(64, activation='relu'),\n","    tf.keras.layers.Dropout(0.2),\n","    tf.keras.layers.Dense(128, activation='relu'),\n","    tf.keras.layers.Dropout(0.2),\n","    tf.keras.layers.Dense(num_classes, activation='softmax')\n","])\n","\n","# Compilar el modelo\n","model.compile(\n","    optimizer='adam',\n","    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n","    metrics=['accuracy']\n",")\n","print (clase)\n"]},{"cell_type":"code","execution_count":null,"id":"253a29a0","metadata":{"id":"253a29a0","outputId":"286faa7c-979c-4bbf-d4d0-2cc011cebfec"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/3\n","64/64 [==============================] - 175s 3s/step - loss: 0.6660 - accuracy: 0.7480 - val_loss: 0.1659 - val_accuracy: 0.9528\n","Epoch 2/3\n","64/64 [==============================] - 169s 3s/step - loss: 0.1445 - accuracy: 0.9505 - val_loss: 0.0775 - val_accuracy: 0.9778\n","Epoch 3/3\n","64/64 [==============================] - 171s 3s/step - loss: 0.0567 - accuracy: 0.9809 - val_loss: 0.0771 - val_accuracy: 0.9833\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x1dbd32a2e50>"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# Entrenar el modelo con los datos redimensionados\n","model.fit(\n","    resized_ds_train,\n","    validation_data=resized_ds_val,\n","    epochs=3,\n","    verbose=1\n",")"]},{"cell_type":"code","execution_count":null,"id":"320f2006","metadata":{"id":"320f2006","outputId":"64cc90ce-41ad-4506-a347-0de06918ac0a"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: C:\\Users\\josea\\AppData\\Local\\Temp\\tmpx0uxsli2\\assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: C:\\Users\\josea\\AppData\\Local\\Temp\\tmpx0uxsli2\\assets\n"]}],"source":["image_min=0,\n","image_max=255.0,\n","mean=[0.0],\n","std=[1.0]\n","converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","tflite_model = converter.convert()\n","tflite_model_file = 'modelo1_5classes.tflite'\n","with open(tflite_model_file, 'wb') as f:\n","    f.write(tflite_model)"]},{"cell_type":"code","execution_count":null,"id":"d662053f","metadata":{"id":"d662053f"},"outputs":[],"source":["from tensorflow.keras.models import Model\n","\n","# Supongamos que tienes un modelo llamado 'modelo' que deseas guardar\n","\n","# Guarda el modelo en un archivo h5\n","model.save('modelo1_5classes.h5')\n"]},{"cell_type":"code","execution_count":null,"id":"3424f96f","metadata":{"id":"3424f96f","outputId":"dc4d5f18-ce97-4fd8-b500-26ed97eb40da"},"outputs":[{"name":"stdout","output_type":"stream","text":["['CUANDO', 'DERECHA', 'DISMINUIR', 'IZQUIERDA', 'SI']\n"]}],"source":["# print the class list\n","print(clase)"]},{"cell_type":"code","execution_count":null,"id":"9d99f56a","metadata":{"id":"9d99f56a","outputId":"d912f2a8-fade-46b5-8aaf-0595643d01ac"},"outputs":[{"name":"stdout","output_type":"stream","text":["(3, 640, 396, 3)\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","import numpy as np\n","\n","# Cargar las imágenes de prueba\n","img = load_img('CUANDO004.jpg')\n","img1 = load_img('DERECHA023.jpg')\n","img2 = load_img('DISMINUIR041.jpg')\n","\n","# Redimensionar las imágenes\n","img = tf.image.resize(img, (640, 396))\n","img1 = tf.image.resize(img1, (640, 396))\n","img2 = tf.image.resize(img2, (640, 396))\n","\n","# Convertir las imágenes a arrays\n","img = img_to_array(img)\n","img1 = img_to_array(img1)\n","img2 = img_to_array(img2)\n","\n","# Crear un array de prueba con las imágenes\n","test = np.array([img, img1, img2])\n","\n","# Imprimir las dimensiones del array de prueba\n","print(test.shape)"]},{"cell_type":"code","execution_count":null,"id":"a7c99a7d","metadata":{"id":"a7c99a7d","outputId":"f9e088ef-b8e8-4c86-ee55-dece24f449a7"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 220ms/step\n"]}],"source":["predicts = model.predict(test)"]},{"cell_type":"code","execution_count":null,"id":"aec1de21","metadata":{"id":"aec1de21","outputId":"eaac7887-a5d5-47b0-b84f-4154526f0c57"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[4.4988416e-02 8.8640565e-01 3.3305366e-02 1.4573127e-02 1.8818395e-02\n","  6.9320214e-04 1.2157894e-03]]\n"]}],"source":["print(predicts)"]},{"cell_type":"code","execution_count":null,"id":"34662285","metadata":{"id":"34662285","outputId":"b85d9d1b-570b-4f60-bf91-0838d8904e6a"},"outputs":[{"name":"stdout","output_type":"stream","text":["El resultado real es LAPTOP la predicción es CUANDO con 100.00%\n","El resultado real es LAPTOP la predicción es DERECHA con 99.79%\n","El resultado real es CELULAR la predicción es DISMINUIR con 100.00%\n"]}],"source":["y1 = np.argmax(predicts[0])\n","y2 = np.argmax(predicts[1])\n","y3 = np.argmax(predicts[2])\n","print(\"El resultado real es LAPTOP la predicción es {} con {:.2f}%\".format(clase[y1], predicts[0][y1]*100))\n","print(\"El resultado real es LAPTOP la predicción es {} con {:.2f}%\".format(clase[y2], predicts[1][y2]*100))\n","print(\"El resultado real es CELULAR la predicción es {} con {:.2f}%\".format(clase[y3], predicts[2][y3]*100))"]},{"cell_type":"code","execution_count":null,"id":"8a1d0c0f","metadata":{"id":"8a1d0c0f","outputId":"858f61e4-8c16-4549-bdf6-af44c186c7c5"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 56ms/step\n","El resultado real es derecha la predicción es SI con 96.70%\n"]}],"source":["img = load_img('salida.jpg')\n","img = tf.image.resize(img, (640, 396))\n","img = img_to_array(img)\n","test = np.array([img])\n","predicts = model.predict(test)\n","y1 = np.argmax(predicts[0])\n","print(\"El resultado real es derecha la predicción es {} con {:.2f}%\".format(clase[y1], predicts[0][y1]*100))"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}