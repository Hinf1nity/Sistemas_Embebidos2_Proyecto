{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Cargar el módulo de Mediapipe para detección de manos\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# Definir la carpeta de videos\n",
    "videos_folder = \"CUANDO_AUG\"\n",
    "\n",
    "# Definir la carpeta de salida de las imágenes resumen\n",
    "output_folder = \"CUANDO_IMG_AUG\"\n",
    "\n",
    "# Asegurarse de que la carpeta de salida exista\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Obtener la lista de archivos de video en la carpeta\n",
    "video_files = [f for f in os.listdir(videos_folder) if os.path.isfile(os.path.join(videos_folder, f)) and f.endswith((\".mp4\", \".avi\"))]\n",
    "\n",
    "video_folder_name = os.path.basename(videos_folder)\n",
    "contador=161\n",
    "\n",
    "# Configurar Mediapipe para la detección de manos\n",
    "with mp_hands.Hands(static_image_mode=True, max_num_hands=2,\n",
    "                    min_detection_confidence=0.05, min_tracking_confidence=0.05) as hands:\n",
    "\n",
    "    for video_file in video_files:\n",
    "        video_path = os.path.join(videos_folder, video_file)\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "        frame_count = 0\n",
    "        summary_image = np.zeros((396, 704, 3))\n",
    "\n",
    "        while cap.isOpened():\n",
    "            # Leer el siguiente frame\n",
    "            success, image = cap.read()\n",
    "            black_image = np.zeros_like(image)\n",
    "            colors = [(0, 0, 255), (0, 255, 0), (255, 0, 0)] \n",
    "            desired_keypoints = [5, 9, 13] \n",
    "            if not success:\n",
    "                break\n",
    "\n",
    "            # Detección de manos\n",
    "            results_hands = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "            if results_hands.multi_hand_landmarks:\n",
    "                for hand_landmarks in results_hands.multi_hand_landmarks:\n",
    "                    for idx, landmark in enumerate(hand_landmarks.landmark):\n",
    "                        if idx in desired_keypoints:\n",
    "                            x = int(landmark.x * image.shape[1])\n",
    "                            y = int(landmark.y * image.shape[0])\n",
    "\n",
    "                            color = colors[desired_keypoints.index(idx)]  # Obtener el color correspondiente al punto clave\n",
    "                            cv2.circle(black_image, (x, y), 4, color, -1)\n",
    "\n",
    "                summary_image += black_image.astype(np.float32)\n",
    "\n",
    "            frame_count += 1   \n",
    "            if frame_count == 100:\n",
    "                break\n",
    "\n",
    "        summary_image = np.clip(summary_image, 0, 255).astype(np.uint8)\n",
    "\n",
    "        #obtener nombre de la carpeta\n",
    "        #carpeta = video_file.split(\"_\")[0]\n",
    "        image_number = str(contador).zfill(3)\n",
    "        # Obtener el nombre base del archivo de video\n",
    "        #video_base_name = os.path.splitext(video_file)[0]\n",
    "\n",
    "        # Generar el nombre de salida de la imagen resumen\n",
    "        #summary_filename = f\"{video_folder_name}{image_number}.jpg\"\n",
    "        summary_output_name = f\"{video_folder_name}{image_number}.jpg\"\n",
    "        summary_output_path = os.path.join(output_folder, summary_output_name)\n",
    "\n",
    "        # Guardar la imagen resumen\n",
    "        cv2.imwrite(summary_output_path, summary_image)\n",
    "        contador+=1\n",
    "\n",
    "        # Liberar recursos\n",
    "        cap.release()\n",
    "\n",
    "# Cerrar las ventanas abiertas por OpenCV\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
